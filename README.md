# ğŸ§© Reproducibility Package for [Text2Stories]

This repository provides the data, experimental setup, and evaluation scripts used in the paper:

> **[Text2Stories: Evaluating the Alignment Between Stakeholder Interviews and Generated User Stories]**  

---

## ğŸ“ Repository Structure
```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ public_interview/          # Publicly released interview dataset
â”‚   â”œâ”€â”€ public_system_desc/         # Publicly released system description dataset
â”‚   â””â”€â”€ generated_US/               # User stories generated by LLMs for 15 private datasets
â”‚
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ ablation_chunking_alignment_quality/     # Ablation on pairwise vs full-context alignment
â”‚   â”œâ”€â”€ ablation_chunking_blocking_efficiency/   # Ablation on different chunking strategies for blocking efficiency
â”‚   â”œâ”€â”€ ablation_metric_robustness/              # Robustness of the metric for detecting mismatches
â”‚   â”œâ”€â”€ ablation_threshold_calibration/          # Effect of threshold calibration for cross-encoders
â”‚   â”œâ”€â”€ pairwise_alignment_quality/              # Experiments for pairwise alignment quality
â”‚   â”œâ”€â”€ text2stories_metric/                     # Evaluation of correctness and completeness
â”‚   â””â”€â”€ blocking_operator/                       # Evaluation of the blocking operator's efficiency
â”‚
â”œâ”€â”€ train/                          # Training scripts for embedding models used in the blocking operator
â””â”€â”€ README.md
```


---

## ğŸ“¦ Data

The `data/` folder contains:

- `public_interview/`: Publicly released dataset used in our experiments.
- `public_system_desc/` : Publicly released dataset used in our experiments.
- `generated_US/`: Synthetic user stories generated using a large language model (LLM) for **15 non-public datasets**. The original datasets are not shareable due to privacy restrictions.

---

## ğŸ”¬ Experiments

The `eval/` folder replicates all experiments from **Section 6** of the paper, including:

1. **Ablation Studies**:
   - Four ablation experiments to test the contribution of individual components.

2. **Pairwise Alignment Quality**:
   - Evaluates how well our method aligns user stories with elicitation interview chunks.

3. **Correctness and Completeness**:
   - Measures how accurately the generated stories reflect the elicitation interview.

4. **Efficiency of the Blocking Operator**:
   - Benchmarks the runtime and scaling behavior of our blocking mechanism.

---

## â–¶ï¸ Requirements
Requirements are in pyproject.toml (not all requirements are strictly needed for running these scripts)
